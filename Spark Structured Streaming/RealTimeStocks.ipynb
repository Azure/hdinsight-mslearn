{"nbformat_minor": 2, "cells": [{"source": "# Configure libraries and packages", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%configure -f\n{\n    \"conf\": {\n        \"spark.jars.packages\": \"org.apache.spark:spark-sql-kafka-0-10_2.11:2.2.0,\", \n        \"spark.jars.excludes\": \"org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.11\"\n    }\n}", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 805.109130859375, "end_time": 1565739462608.013}}, "collapsed": false}}, {"source": "# Set up Connection to Kafka", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "// Provide your Kafka broker endpoint (including port #)\n\nval inputDf = (spark.readStream\n  .format(\"kafka\")\n  .option(\"kafka.bootstrap.servers\", \"\")\n  .option(\"subscribe\", \"stockVals\")\n  .option(\"startingOffsets\", \"earliest\") \n  .load()\n  )", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 2303.72705078125, "end_time": 1565739487541.386}}, "collapsed": false}}, {"source": "# Read from Kafka into Streaming Dataframe", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import org.apache.spark.sql._\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.functions._\n\nval stockJsonDf = inputDf.selectExpr(\"CAST(value AS STRING)\")\nval stockSchema = (new StructType()\n  .add(\"symbol\", DataTypes.StringType)\n  .add(\"time\", DataTypes.StringType)\n  .add(\"price\", DataTypes.FloatType)\n  .add(\"size\", DataTypes.IntegerType)\n  )\nval stockNestedJsonDf = stockJsonDf.select(from_json($\"value\", stockSchema).as(\"stockRecord\"))\nval stockFlatDf = stockNestedJsonDf.selectExpr(\"stockRecord.symbol\", \"stockRecord.time\", \"stockRecord.price\", \"stockRecord.size\")\nval stockDf = stockFlatDf.withColumn(\"time\", from_unixtime($\"time\"/1000))", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 3295.920166015625, "end_time": 1565739548054.057}}, "collapsed": false}}, {"source": "# Output Streaming Dataframe to Console", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "(stockDf.writeStream\n  .outputMode(\"append\")\n  .format(\"console\")\n  .start()\n  .awaitTermination(10000)\n)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 13325.952880859375, "end_time": 1565739588112.614}}, "collapsed": false}}, {"source": "# Windowed Stock Min / Max", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "(stockDf.groupBy(\n  window($\"time\", \"4 seconds\"),\n  $\"symbol\"\n  ).agg(max($\"price\"), min($\"price\"))\n  .writeStream\n  .format(\"console\")\n  .outputMode(\"complete\")\n  .start()\n  .awaitTermination(30000)\n)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 31393.27099609375, "end_time": 1565739702512.82}}, "collapsed": false}}, {"source": "# Collect all values for a stock", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "(stockDf.groupBy(\n  window($\"time\", \"4 seconds\"),\n  $\"symbol\"\n).agg(collect_list($\"price\"))\n  .writeStream\n  .format(\"console\")\n  .outputMode(\"complete\")\n  .start()\n  .awaitTermination(30000)\n)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 31370.406005859375, "end_time": 1565710875608.259}}, "collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Spark", "name": "sparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-scala", "pygments_lexer": "scala", "name": "scala", "codemirror_mode": "text/x-scala"}}}